[tool.poetry]
name = "mlops-ii-course"
version = "0.1.0"
description = "Dependencias del curso de Machine Learning Ops II. Gestión de proyectos con Poetry."
authors = ["Jaime Riascos <jandresrsalas@gmail.com>"]
license = "MIT" # O la licencia que prefieras
readme = "README.md"
# Más información sobre curso ML Ops 1:
repository = "https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/aprendizaje_maquina_II"


keywords = ["MLOps", "Machine Learning", "Python", "FastAPI", "Airflow", "MLflow"]

[tool.poetry.dependencies]
python = ">=3.9,<3.12" # Versión de Python recomendada para el curso (por ejemplo, 3.9, 3.10, 3.11)

# Dependencias Core de Ciencia de Datos y Machine Learning
numpy = "^1.26.4"      # Fundamento para computación numérica
pandas = "^2.2.2"      # Manipulación y análisis de datos
scikit-learn = "^1.4.2" # Algoritmos de Machine Learning
joblib = "^1.4.2"      # Para guardar y cargar modelos de forma eficiente
matplotlib = "^3.9.0"  # Visualización de datos
seaborn = "^0.13.2"    # Visualización de datos (basado en matplotlib)

# Herramientas Core de MLOps
fastapi = "^0.111.0"   # Framework para construir APIs web (muy usado en MLOps para inferencia)
uvicorn = {extras = ["standard"], version = "^0.29.0"} # Servidor ASGI para FastAPI (con optimizaciones)
pydantic = "^2.7.1"    # Validación y serialización de datos con FastAPI
mlflow = "^2.13.0"     # Tracking de experimentos, registro y despliegue de modelos
requests = "^2.32.3"   # Para que los clientes Python interactúen con APIs

# Apache Airflow y Proveedores (para orquestación de pipelines)
# Se recomienda una versión específica o un rango para mantener la compatibilidad durante el curso.
apache-airflow = ">=2.6.0,<2.9.0"
# Proveedores esenciales para integrar Airflow con otras herramientas
apache-airflow-providers-cncf-kubernetes = "^7.12.0" # Si se explora despliegue en Kubernetes con Airflow
apache-airflow-providers-docker = "^4.2.0"          # Para ejecutar tareas en contenedores Docker
apache-airflow-providers-postgres = "^5.10.0"       # Para interactuar con bases de datos PostgreSQL
apache-airflow-providers-sqlite = "^4.0.0"          # Útil para el backend local de Airflow en desarrollo
psycopg2-binary = "^2.9.9" # Adaptador de PostgreSQL para Python
sqlalchemy = "^2.0.30" # ORM de Python, base para muchas conexiones a DB

# Data Lake (compatible con S3/MinIO)
boto3 = "^1.34.116"    # SDK de AWS para Python, compatible con MinIO (Data Lake local)
minio = "^7.2.5"       # Cliente Python para MinIO (útil para interacciones directas con el Data Lake)

# Streaming (para ejemplos de procesamiento de datos en tiempo real)
redis = "^5.0.0"       # Para Redis Streams (una opción ligera para ejemplos de streaming)
# Si se desea profundizar en Kafka, se requerirían: confluent-kafka = "^2.4.0" o kafka-python = "^2.0.2"

# Comunicación Avanzada de APIs (GraphQL y gRPC)
strawberry-graphql = {extras = ["fastapi"], version = "^0.222.1"} # Implementación moderna de GraphQL para FastAPI
grpcio = "^1.64.0"     # Librería principal de gRPC
grpcio-tools = "^1.64.0" # Herramientas para generar código a partir de archivos .proto

[tool.poetry.group.dev.dependencies]
# Herramientas para el desarrollo y el entorno de Jupyter
ipykernel = "^6.29.4"  # Kernel de Python para Jupyter Notebooks
jupyter = "^1.0.0"     # Meta-paquete que instala herramientas clave de Jupyter
# Herramientas de formateo y linting (buenas prácticas de desarrollo)
black = "^24.4.2"      # Formateador de código
isort = "^5.13.2"      # Ordena las importaciones
flake8 = "^7.1.0"      # Linter para verificar el estilo y errores del código

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"