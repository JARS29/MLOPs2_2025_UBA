{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tutorial Práctico de Aprendizaje Federado y Seguridad\n",
        "\n",
        "Este tutorial se ha ajustado para asegurar un entrenamiento exitoso del modelo y para demostrar de manera clara el impacto de un ataque de envenenamiento de datos. Se ha corregido la forma de manejar los optimizadores y las épocas, y se ha añadido la lógica para guardar el gráfico de resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Paso 1: Archivos del Proyecto**\n",
        "\n",
        "Asegúrate de que tu proyecto tenga la siguiente estructura:\n",
        "\n",
        "* **`pyproject.toml`**\n",
        "* **`Dockerfile`**\n",
        "* **`tutorial_federado.py`** (El contenido actualizado se proporciona a continuación)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Paso 2: Contenido del Archivo `tutorial_federado.py`**\n",
        "\n",
        "Este es el script completo con todas las correcciones, incluyendo la sintaxis, la configuración de los optimizadores, la asignación de pesos y la gestión de épocas por ronda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---- 1) Cargar y preprocesar datos EMNIST ----\n",
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n",
        "\n",
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 32\n",
        "ROUNDS = 50\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "def create_client_data(client_id):\n",
        "    return emnist_train.create_tf_dataset_for_client(client_id)\n",
        "\n",
        "def preprocess_dataset(dataset):\n",
        "    def flatten_and_normalize(element):\n",
        "        image = tf.cast(element['pixels'], tf.float32) / 255.0\n",
        "        image = tf.reshape(image, [-1])\n",
        "        label = tf.cast(element['label'], tf.int32)\n",
        "        return image, label\n",
        "    \n",
        "    return dataset.map(flatten_and_normalize).repeat(NUM_EPOCHS).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "client_ids = emnist_train.client_ids[:NUM_CLIENTS]\n",
        "federated_train_data = [preprocess_dataset(create_client_data(cid)) for cid in client_ids]\n",
        "\n",
        "# ---- Dataset de prueba (global) ----\n",
        "test_dataset = emnist_test.create_tf_dataset_from_all_clients()\n",
        "test_dataset = preprocess_dataset(test_dataset)\n",
        "\n",
        "# ---- 2) Modelo Keras ----\n",
        "def create_keras_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Input(shape=(784,)),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def model_fn():\n",
        "    keras_model = create_keras_model()\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model,\n",
        "        input_spec=federated_train_data[0].element_spec,\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "# ---- 3) Algoritmo FedAvg ----\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=tff.learning.optimizers.build_sgdm(learning_rate=0.5),\n",
        "    server_optimizer_fn=tff.learning.optimizers.build_sgdm(learning_rate=1.0),\n",
        "    client_weighting=tff.learning.ClientWeighting.NUM_EXAMPLES,\n",
        ")\n",
        "\n",
        "# ---- 4) Evaluación global y por clase ----\n",
        "def evaluate_model(state):\n",
        "    keras_model = create_keras_model()\n",
        "    model_weights = iterative_process.get_model_weights(state)\n",
        "    model_weights.assign_weights_to(keras_model)\n",
        "    \n",
        "    acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    loss = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
        "    per_class_acc = {i: [0, 0] for i in range(10)}\n",
        "\n",
        "    for x, y in test_dataset:\n",
        "        preds = keras_model(x, training=False)\n",
        "        acc.update_state(y, preds)\n",
        "        loss.update_state(y, preds)\n",
        "        y_pred = tf.argmax(preds, axis=1)\n",
        "        for label, pred in zip(y.numpy(), y_pred.numpy()):\n",
        "            per_class_acc[int(label)][1] += 1\n",
        "            if label == pred:\n",
        "                per_class_acc[int(label)][0] += 1\n",
        "\n",
        "    per_class_acc_pct = {cls: (hits / total if total > 0 else 0.0)\n",
        "                         for cls, (hits, total) in per_class_acc.items()}\n",
        "    return acc.result().numpy(), loss.result().numpy(), per_class_acc_pct\n",
        "\n",
        "# ---- 5) Función para imprimir métricas por ronda ----\n",
        "def print_metrics(round_num, metrics, eval_acc, eval_loss):\n",
        "    tm = metrics['client_work']['train']\n",
        "    print(f\"Ronda {round_num:2d} | \"\n",
        "          f\"Train Acc: {tm['sparse_categorical_accuracy']:.4f} | \"\n",
        "          f\"Train Loss: {tm['loss']:.4f} | \"\n",
        "          f\"Eval Acc: {eval_acc:.4f} | \"\n",
        "          f\"Eval Loss: {eval_loss:.4f} | \"\n",
        "          f\"Ejemplos: {tm['num_examples']}\")\n",
        "\n",
        "# ---- 6) Preparar dataset envenenado ----\n",
        "def poison_raw_dataset(raw_ds):\n",
        "    def swap_labels(elem):\n",
        "        image = elem['pixels']\n",
        "        label = tf.cast(elem['label'], tf.int32)\n",
        "        label = tf.where(tf.equal(label, 3), tf.constant(7, dtype=tf.int32), label)\n",
        "        label = tf.where(tf.equal(label, 7), tf.constant(3, dtype=tf.int32), label)\n",
        "        return {'pixels': image, 'label': label}\n",
        "    return raw_ds.map(swap_labels)\n",
        "\n",
        "poisoned_federated_train_data = list(federated_train_data)\n",
        "raw_client0 = create_client_data(client_ids[0])\n",
        "poisoned_raw0 = poison_raw_dataset(raw_client0)\n",
        "poisoned_federated_train_data[0] = preprocess_dataset(poisoned_raw0)\n",
        "\n",
        "# ---- 7) Entrenamiento y registro de métricas ----\n",
        "results_clean = []\n",
        "results_poison = []\n",
        "\n",
        "print(\"--- Entrenamiento SIN Ataque ---\")\n",
        "state = iterative_process.initialize()\n",
        "for round_num in range(1, ROUNDS + 1):\n",
        "    result = iterative_process.next(state, federated_train_data)\n",
        "    state = result.state\n",
        "    eval_acc, eval_loss, _ = evaluate_model(state)\n",
        "    print_metrics(round_num, result.metrics, eval_acc, eval_loss)\n",
        "    results_clean.append(eval_acc)\n",
        "\n",
        "print(\"\\n--- Entrenamiento CON Ataque de Envenenamiento (cliente 0) ---\")\n",
        "state_poison = iterative_process.initialize()\n",
        "for round_num in range(1, ROUNDS + 1):\n",
        "    result = iterative_process.next(state_poison, poisoned_federated_train_data)\n",
        "    state_poison = result.state\n",
        "    eval_acc, eval_loss, per_class_acc = evaluate_model(state_poison)\n",
        "    print_metrics(round_num, result.metrics, eval_acc, eval_loss)\n",
        "    if round_num == ROUNDS:\n",
        "        print(\"\\nPrecisión por clase en última ronda (con ataque):\")\n",
        "        for cls in range(10):\n",
        "            print(f\"Clase {cls}: {per_class_acc[cls]:.4f}\")\n",
        "    results_poison.append(eval_acc)\n",
        "\n",
        "# ---- 8) Gráfico de precisión global ----\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(range(1, ROUNDS+1), results_clean, label=\"Sin ataque\")\n",
        "plt.plot(range(1, ROUNDS+1), results_poison, label=\"Con ataque\", linestyle='--')\n",
        "plt.xlabel(\"Ronda\")\n",
        "plt.ylabel(\"Precisión global en test\")\n",
        "plt.title(\"Efecto del envenenamiento de datos\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"/app/envenenamiento_precision.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Paso 3: Contenido del Archivo `pyproject.toml`**\n",
        "\n",
        "Este archivo de configuración se ha actualizado para garantizar la compatibilidad de las librerías."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[tool.poetry]\n",
        "name = \"mlops-ii\"\n",
        "version = \"0.1.0\"\n",
        "description = \"\"\n",
        "authors = [\"Your Name <you@example.com>\"]\n",
        "\n",
        "\n",
        "[tool.poetry.dependencies]\n",
        "python = \">=3.9, <3.11\" \n",
        "tensorflow = \"2.14.0\" \n",
        "tensorflow-federated = \">=0.60.0\"\n",
        "numpy = \">=1.18.5, <1.26.0\"\n",
        "matplotlib = \">=3.7.0, <3.9.0\"\n",
        "\n",
        "\n",
        "[build-system]\n",
        "requires = [\"poetry-core\"]\n",
        "build-backend = \"poetry.core.masonry.api\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Paso 4: Contenido del Archivo `Dockerfile`**\n",
        "\n",
        "Este `Dockerfile` es el que debes usar para construir la imagen de Docker. No requiere cambios adicionales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FROM python:3.10-slim\n",
        "\n",
        "RUN pip install poetry\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "COPY pyproject.toml .\n",
        "\n",
        "RUN poetry install --no-root\n",
        "\n",
        "COPY tutorial_federado.py .\n",
        "\n",
        "CMD [\"poetry\", \"run\", \"python\", \"tutorial_federado.py\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Paso 5: Comando de Ejecución para Windows**\n",
        "\n",
        "Utiliza el siguiente comando en tu terminal de Windows. Este comando ejecuta el script y monta la carpeta local en el contenedor, lo que te permitirá acceder al gráfico generado.\n",
        "\n",
        "#### **Si usas PowerShell:**\n",
        "\n",
        "```powershell\n",
        "docker run --rm -v ${pwd}:/app federated-mlops\n",
        "```\n",
        "\n",
        "#### **Si usas Command Prompt (CMD):**\n",
        "\n",
        "```cmd\n",
        "docker run --rm -v \"%cd%\":/app federated-mlops\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
